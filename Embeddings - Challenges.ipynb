{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Embeddings\n",
        "## Understand embeddings and how they can be used to perform a variety of tasks, including semantic search.\n",
        "\n",
        "> **Notice**: This notebook is not saved automatically. If you're using Google Colab, make sure to save a copy to your Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Introduction\n",
        "\n",
        "Welcome to the interactive challenge notebook for the lesson on **Embeddings**. In this session, we're going to dive deep into how embeddings work and see them in action. Embeddings are powerful representations that allow us to capture semantic relationships between entities, which can be incredibly useful in tasks like semantic search, natural language processing, and more.\n",
        "\n",
        "By the end of this notebook, you'll get hands-on experience with implementing semantic search using embeddings and understand how they can be applied to solve real-world problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 1: Load a Pre-trained Word Embedding Model\n",
        "\n",
        "**Task**: Load a pre-trained word embedding model using `gensim`.\n",
        "\n",
        "```python\n",
        "# TODO: Install gensim if necessary\n",
        "# !pip install gensim\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# TODO: Load a pre-trained embedding model (GoogleNews vectors as an example)\n",
        "# Hint: Use KeyedVectors.load_word2vec_format with the appropriate file path for the embeddings.\n",
        "word_vectors = None  # Replace None with your code to load the model\n",
        "```\n",
        "\n",
        "Don't forget to download and have the GoogleNews vectors or any other word vectors you prefer ready. You might need to download these outside of this notebook and upload them in your environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 2: Define a Semantic Search Function\n",
        "\n",
        "**Task**: Define a function that takes a query as input and finds the most similar items in the embedding space.\n",
        "\n",
        "```python\n",
        "def semantic_search(query, word_vectors, top_n=5):\n",
        "    # TODO: Implement the function to find the most similar words using the word_vectors\n",
        "    # You might find the 'most_similar' function of KeyedVectors useful\n",
        "    results = []  # This should be replaced with your implementation\n",
        "    return results\n",
        "\n",
        "# Test the function\n",
        "# TODO: Replace 'sample_query' with actual words to test your function\n",
        "sample_query = ''  # replace this with a meaningful query\n",
        "print(semantic_search(sample_query, word_vectors))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 3: Explore Different Queries\n",
        "\n",
        "Now that you have implemented the semantic search function, it's your turn to explore.\n",
        "\n",
        "**Tasks**:\n",
        "- Try different queries and observe the results.\n",
        "- Think about why certain words are considered similar and others are not.\n",
        "\n",
        "```python\n",
        "# TODO: Try at least three different queries to explore semantic similarities\n",
        "query_1 = ''  # Add your first query\n",
        "print('Query results for:', query_1)\n",
        "print(semantic_search(query_1, word_vectors))\n",
        "\n",
        "# Add more queries as you like\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Thoughts\n",
        "\n",
        "We have just scratched the surface of what's possible with embeddings. They're a fundamental part of the machinery behind many of today's AI capabilities, especially in natural language processing tasks. As you've seen in this lesson, one of their powerful applications is in semantic search, where they can quickly bring relevant answers to complex queries.\n",
        "\n",
        "Congratulations on completing the practical challenges on embeddings! We encourage you to experiment further with different models and datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit Your Work\n",
        "\n",
        "Please download this notebook and email it as an attachment to the instructor for review. Here's how you can download the notebook:\n",
        "\n",
        "- In Google Colab, go to **File** -> **Download** -> **Download .ipynb**.\n",
        "- Attach the downloaded `.ipynb` file in an email to **o.j.uwaifo@gmail.com**.\n",
        "\n",
        "Good luck, and feel free to reach out if you have any questions or need further clarification."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}